{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zOxZ3W1YqRw",
        "outputId": "5ed329a7-0566-4791-b187-3036d18fe521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "stop_words = stopwords.words()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/twitter_training.csv')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "uHa1bny4ZRFQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "_WodAcbwaLyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'review':'text'}, inplace = True)\n",
        "df"
      ],
      "metadata": {
        "id": "kJ4pMQDIaTXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt['no_sw'] = dt['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
      ],
      "metadata": {
        "id": "guh2DQ5saafH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt"
      ],
      "metadata": {
        "id": "inXJ04RtajwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb=dt.drop(columns=['text','no_sw', 'wo_stopfreq'])\n",
        "nb.columns=['sentiment','review']\n",
        "nb.sentiment = [0 if each == \"negative\" else 1 for each in nb.sentiment]\n",
        "nb"
      ],
      "metadata": {
        "id": "i2Q7dzstak0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_review=nb['review'].apply(lambda x: x.split())\n",
        "tokenized_review.head(5)"
      ],
      "metadata": {
        "id": "WL9xe__IasSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "text_counts = cv.fit_transform(nb['review'])"
      ],
      "metadata": {
        "id": "zGZYZTJkazB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X=text_counts\n",
        "y=nb['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=30)"
      ],
      "metadata": {
        "id": "Y1AjMnZOa1m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train, y_train)\n",
        "\n",
        "predicted = MNB.predict(X_test)\n",
        "accuracy_score = metrics.accuracy_score(predicted, y_test)\n",
        "\n",
        "print('MultinominalNB model accuracy is',str('{:04.2f}'.format(accuracy_score*100))+'%')\n",
        "print('------------------------------------------------')\n",
        "print('Confusion Matrix:')\n",
        "print(pd.DataFrame(confusion_matrix(y_test, predicted)))\n",
        "print('------------------------------------------------')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, predicted))"
      ],
      "metadata": {
        "id": "LGvamWWva5dI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "df = pd.read_csv('/content/twitter_training.csv')\n",
        "\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train, y_train)\n",
        "\n",
        "predicted_MNB = MNB.predict(X_test)\n",
        "accuracy_score_MNB = metrics.accuracy_score(y_test, predicted_MNB)\n",
        "\n",
        "print('MultinomialNB model accuracy is', str('{:04.2f}'.format(accuracy_score_MNB * 100)) + '%')\n",
        "print('------------------------------------------------')\n",
        "print('Confusion Matrix:')\n",
        "print(pd.DataFrame(confusion_matrix(y_test, predicted_MNB)))\n",
        "print('------------------------------------------------')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, predicted_MNB))\n",
        "\n",
        "GNB = GaussianNB()\n",
        "\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "GNB.fit(X_train_dense, y_train)\n",
        "\n",
        "predicted_GNB = GNB.predict(X_test_dense)\n",
        "accuracy_score_GNB = metrics.accuracy_score(y_test, predicted_GNB)\n",
        "\n",
        "print('GaussianNB model accuracy is', str('{:04.2f}'.format(accuracy_score_GNB * 100)) + '%')\n",
        "print('------------------------------------------------')\n",
        "print('Confusion Matrix:')\n",
        "print(pd.DataFrame(confusion_matrix(y_test, predicted_GNB)))\n",
        "print('------------------------------------------------')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, predicted_GNB))"
      ],
      "metadata": {
        "id": "6HzYvfOCbILS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}